# Pipeline ML avec MLflow + Airflow + Grafana

Une stack complÃ¨te de machine learning avec orchestration, tracking et monitoring de drift.

## ğŸ—ï¸ Architecture

- **Apache Airflow**: Orchestration du pipeline ML
- **MLflow**: Tracking des expÃ©riences et model registry
- **Grafana**: Dashboards de monitoring et alerting
- **Prometheus**: Collecte des mÃ©triques custom
- **PostgreSQL**: Backend pour Airflow et MLflow

## ğŸ“ Structure du projet

```
project/
â”œâ”€â”€ docker-compose.yml          # Configuration Docker Compose
â”œâ”€â”€ prometheus.yml              # Configuration Prometheus
â”œâ”€â”€ init-db.sql                # Script d'initialisation DB
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ ml_pipeline.py      # DAG principal du pipeline ML
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances Python Airflow
â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ Dockerfile              # Image MLflow custom
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances Python MLflow
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â””â”€â”€ dashboards.yml  # Configuration dashboards
â”‚   â”‚   â””â”€â”€ datasources/
â”‚   â”‚       â””â”€â”€ datasources.yml # Configuration datasources
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ ml-monitoring.json  # Dashboard ML monitoring
â”œâ”€â”€ data/                       # DonnÃ©es (volume Docker)
â””â”€â”€ monitoring/
    â””â”€â”€ drift_detector.py       # DÃ©tecteur de drift
```

## ğŸš€ DÃ©marrage rapide

### 1. Cloner et naviguer vers le projet

```bash
git clone <repository>
cd PART_4
```

### 2. Lancer la stack

```bash
docker-compose up -d
```

### 3. VÃ©rifier le dÃ©ploiement

Attendre que tous les services soient UP (peut prendre 2-3 minutes):

```bash
docker-compose ps
```

### 4. AccÃ©der aux interfaces

- **Airflow**: http://localhost:8080
  - Username: `admin`
  - Password: `admin`

- **MLflow**: http://localhost:5001

- **Grafana**: http://localhost:3000
  - Username: `admin`
  - Password: `admin`

- **Prometheus**: http://localhost:9090

## ğŸ“Š Pipeline ML

### TÃ¢ches du DAG Airflow

1. **load_data**: Chargement des donnÃ©es depuis `/data`
2. **preprocess_data**: Preprocessing et split train/val/test
3. **train_model**: EntraÃ®nement MLPClassifier
4. **evaluate_model**: Calcul des mÃ©triques de performance
5. **detect_drift**: DÃ©tection de drift vs modÃ¨le prÃ©cÃ©dent
6. **log_metrics_to_prometheus**: Envoi mÃ©triques vers Prometheus
7. **register_model**: Enregistrement dans MLflow Model Registry

### MÃ©triques trackÃ©es

#### ğŸš¨ **MÃ©triques FRAUD-FOCUSED (les vraies mÃ©triques qui comptent !)**

**Performance Classe Fraude (Classe 1):**
- `test_fraud_f1` : F1-Score spÃ©cifique Ã  la dÃ©tection de fraude (â‰ˆ 0.80)
- `test_fraud_precision` : PrÃ©cision sur les fraudes dÃ©tectÃ©es (â‰ˆ 0.84)
- `test_fraud_recall` : Rappel des fraudes (â‰ˆ 0.77) - **CRITIQUE** pour Ã©viter les pertes

**Impact Business:**
- `fraud_detection_rate` : Taux de dÃ©tection des fraudes (0.77 = 77% des fraudes dÃ©tectÃ©es)
- `frauds_detected_count` : Nombre de fraudes dÃ©tectÃ©es (76 âœ…)
- `frauds_missed_count` : **Nombre de fraudes ratÃ©es** (23 âš ï¸ - COÃ›T FINANCIER)
- `false_alarm_rate` : Taux de fausses alertes (0.02% - impact opÃ©rationnel)
- `false_alarms_count` : Nombre de transactions lÃ©gitimes bloquÃ©es (14)

#### ğŸ“Š **MÃ©triques Globales (pour comparaison)**

**Performance GÃ©nÃ©rale:**
- F1 Score (macro, weighted) - moyennes qui diluent les performances fraud
- PrÃ©cision/Recall globaux - dominÃ©s par la classe majoritaire (99.83%)
- ~~Accuracy~~ - **SUPPRIMÃ‰E** car trompeuse sur donnÃ©es dÃ©sÃ©quilibrÃ©es

**Drift Detection:**
- `drift_score` : Score global de dÃ©rive des donnÃ©es (0-1)
- `n_drifted_features` : Nombre de features ayant dÃ©rivÃ©
- `max_feature_drift` : Score maximum de dÃ©rive par feature

#### âš ï¸ **POURQUOI CES MÃ‰TRIQUES SONT CRUCIALES ?**

Le dataset creditcard.csv est **ultra-dÃ©sÃ©quilibrÃ©** :
- 99.83% transactions normales vs 0.17% fraudes
- Un modÃ¨le "naÃ¯f" qui prÃ©dit toujours "normal" obtient 99.83% d'accuracy !
- **Les vraies performances se mesurent sur la classe minoritaire (fraude)**

**Exemple concret avec vos rÃ©sultats actuels :**
```
test_fraud_f1: 0.804 (80.4% F1-Score sur la fraude)
test_fraud_precision: 0.844 (84.4% des alertes sont de vraies fraudes)  
test_fraud_recall: 0.768 (76.8% des fraudes sont dÃ©tectÃ©es)
fraud_detection_rate: 0.768 (76.8% taux de dÃ©tection)
frauds_detected_count: 76 (fraudes attrapÃ©es âœ…)
frauds_missed_count: 23 (fraudes ratÃ©es âš ï¸ - PERTE FINANCIÃˆRE)
false_alarms_count: 14 (clients gÃªnÃ©s inutilement)
false_alarm_rate: 0.0002 (0.02% de fausses alertes)
```

**InterprÃ©tation Business :**
- âœ… **76 fraudes dÃ©tectÃ©es** = Pertes Ã©vitÃ©es (si fraude moyenne = 100â‚¬, Ã©conomies = 7,600â‚¬)
- âš ï¸ **23 fraudes ratÃ©es** = Pertes subies (2,300â‚¬ de pertes non Ã©vitÃ©es)  
- ğŸ“Š **14 fausses alertes** = GÃªne client minime (0.02% des transactions)
- ğŸ¯ **Performance globale** : Correcte mais **23% de fraudes ratÃ©es reste Ã©levÃ©**

## ğŸ” Monitoring et alerting

### Dashboard Grafana

Le dashboard "ML Model Monitoring" inclut **6 panels fraud-focused** :

1. **ğŸš¨ FRAUD Detection Performance** : F1, Precision, Recall de la classe fraude
2. **ğŸ’° Business Impact** : Fraudes dÃ©tectÃ©es vs manquÃ©es, fausses alertes
3. **ğŸ¯ Performance Over Time** : Ã‰volution temporelle des mÃ©triques fraud
4. **Data Drift Metrics** : DÃ©tection de dÃ©rive des donnÃ©es
5. **Drift Score Over Time** : Ã‰volution de la dÃ©rive
6. **Drifted Features Count** : Nombre de features ayant dÃ©rivÃ©

### Seuils d'alerte BUSINESS-ORIENTED

**MÃ©triques Fraude (seuils adaptÃ©s Ã  l'impact business) :**
- ğŸ”´ **Critique** : Fraud Recall < 60% (trop de fraudes ratÃ©es)
- ğŸŸ¡ **Attention** : Fraud Recall 60-80% (performance acceptable)
- ğŸŸ¢ **Bon** : Fraud Recall > 80% (excellente dÃ©tection)

**Impact Business :**
- ğŸ”´ **Critique** : > 25 fraudes manquÃ©es par run
- ğŸŸ¡ **Attention** : 10-25 fraudes manquÃ©es
- ğŸŸ¢ **Acceptable** : < 10 fraudes manquÃ©es

**Drift (impact sur la stabilitÃ© du modÃ¨le) :**
- ğŸŸ¢ **Stable** : Drift score < 0.1
- ğŸŸ¡ **Surveillance** : Drift score 0.1-0.3
- ğŸ”´ **Re-entraÃ®nement** : Drift score > 0.3

## ğŸ“‚ DonnÃ©es

### Utilisation de donnÃ©es existantes

1. Placer vos fichiers CSV dans le dossier `data/`
2. Le pipeline chargera automatiquement le premier CSV trouvÃ©
3. Assurez-vous que la derniÃ¨re colonne soit la target

### DonnÃ©es synthÃ©tiques

Si aucun CSV n'est trouvÃ©, le pipeline gÃ©nÃ¨re automatiquement des donnÃ©es synthÃ©tiques pour la dÃ©monstration.

## âš™ï¸ Configuration

### Variables d'environnement

Les principales variables sont configurÃ©es dans `docker-compose.yml`:
- `MLFLOW_TRACKING_URI`
- `PROMETHEUS_PUSHGATEWAY_URL`
- Credentials PostgreSQL

### Personnalisation du modÃ¨le

Modifier les paramÃ¨tres dans `airflow/dags/ml_pipeline.py`:
- Architecture du MLPClassifier
- Seuils de drift
- CritÃ¨res d'enregistrement du modÃ¨le

## ğŸ› ï¸ Commandes utiles

### RedÃ©marrer un service

```bash
docker-compose restart <service_name>
```

### Voir les logs

```bash
docker-compose logs -f <service_name>
```

### AccÃ©der Ã  un container

```bash
docker-compose exec <service_name> bash
```

### Nettoyer et redÃ©marrer

```bash
docker-compose down -v
docker-compose up -d
```

## ğŸ“‹ Troubleshooting

### Services qui ne dÃ©marrent pas

1. VÃ©rifier les logs: `docker-compose logs <service_name>`
2. S'assurer que les ports ne sont pas occupÃ©s
3. VÃ©rifier l'espace disque disponible

### Pipeline Airflow qui Ã©choue

1. Aller dans l'interface Airflow
2. Consulter les logs des tÃ¢ches Ã©chouÃ©es
3. VÃ©rifier les dÃ©pendances Python
4. S'assurer que MLflow est accessible

### MÃ©triques manquantes dans Grafana

1. VÃ©rifier que Prometheus scrape les mÃ©triques
2. S'assurer que le pushgateway reÃ§oit les donnÃ©es
3. VÃ©rifier la configuration des datasources Grafana

## ğŸ”„ Workflow typique

1. **DÃ©veloppement**: Modifier le code dans `airflow/dags/` ou `monitoring/`
2. **Test**: DÃ©clencher manuellement le DAG dans Airflow
3. **Monitoring**: Observer les mÃ©triques dans Grafana
4. **ItÃ©ration**: Ajuster les seuils et paramÃ¨tres selon les rÃ©sultats

## ğŸš€ AmÃ©liorations pour optimiser la dÃ©tection de fraude

### ğŸ’¡ **Techniques pour rÃ©duire les fraudes ratÃ©es (23 â†’ < 10)**

1. **RÃ©Ã©quilibrage des classes :**
   - **SMOTE** : SynthÃ¨se de nouvelles fraudes artificielles
   - **Undersampling** : RÃ©duire la classe majoritaire  
   - **Class weights** : PÃ©naliser plus les erreurs sur la classe fraude

2. **Optimisation des hyperparamÃ¨tres :**
   - **Seuil de dÃ©cision** : Abaisser le seuil (favorise recall vs precision)
   - **Architecture rÃ©seau** : Plus de couches, dropout, regularization
   - **Fonction de coÃ»t** : Focal loss pour classes dÃ©sÃ©quilibrÃ©es

3. **ModÃ¨les spÃ©cialisÃ©s :**
   - **XGBoost/LightGBM** : TrÃ¨s efficaces sur donnÃ©es tabulaires dÃ©sÃ©quilibrÃ©es
   - **Isolation Forest** : DÃ©tection d'anomalies non supervisÃ©e
   - **Ensemble methods** : Combiner plusieurs modÃ¨les

4. **Feature engineering :**
   - **DÃ©rivÃ©es temporelles** : Variations de comportement
   - **AgrÃ©gations** : Historique transactionnel par client
   - **Ratios** : Montant vs historique client

### ğŸ“Š **MÃ©triques business avancÃ©es**

5. **Optimisation par coÃ»t-bÃ©nÃ©fice :**
   - DÃ©finir le **coÃ»t d'une fraude ratÃ©e** vs **coÃ»t d'une fausse alerte**
   - Optimiser le **seuil de dÃ©cision** selon l'Ã©quation business
   - Calculer le **ROI du modÃ¨le** (gains Ã©vitÃ©s vs coÃ»ts opÃ©rationnels)

## ğŸ“ˆ Extensions possibles

- **Alerting temps rÃ©el**: Notifications Slack/email quand > 10 fraudes ratÃ©es
- **A/B Testing**: Comparer MLPClassifier vs XGBoost vs LightGBM
- **Feature Store**: IntÃ©grer un feature store (Feast) pour l'historique client
- **Model Serving**: Ajouter un service de prÃ©diction temps rÃ©el (FastAPI)
- **CI/CD**: IntÃ©grer avec GitHub Actions pour dÃ©ploiement automatique
- **AutoML**: Hyperparameter tuning automatisÃ© (Optuna, Hyperopt)

## ğŸ› Debugging

### Logs dÃ©taillÃ©s

```bash
# Logs Airflow scheduler
docker-compose logs -f airflow-scheduler

# Logs MLflow
docker-compose logs -f mlflow

# Logs PostgreSQL
docker-compose logs -f postgres
```

### VÃ©rification des connexions

```bash
# Test connexion PostgreSQL
docker-compose exec postgres psql -U airflow -d airflow -c "\\l"

# Test API MLflow
curl http://localhost:5000/health

# Test Prometheus targets
curl http://localhost:9090/api/v1/targets
```